## ADDED Requirements

### Requirement: Static visual reports
The system SHALL produce reproducible static visual reports (PNG/HTML) that summarize model evaluation: precision, recall, F1, ROC AUC, confusion matrix, and example predictions. Reports SHALL be generated by `src/report.py` and written under a specified output directory.

#### Scenario: Generate static report
- **WHEN** `python src/report.py --model models/logreg --out reports/` is executed
- **THEN** `reports/` SHALL contain `eval_report.json`, `confusion_matrix.png`, `roc.png`, `pr.png`, and `examples.csv` containing example predictions

### Requirement: Interactive Streamlit dashboard
The repository SHALL provide a Streamlit application that loads a trained model and allows users to:
- View evaluation metrics and charts
- Run single-text inference and show predicted label and probability
- Upload a CSV for batch inference and download predictions
- Adjust probability threshold and see updated metrics

#### Scenario: Run Streamlit UI
- **WHEN** a developer runs `streamlit run tools/streamlit_app.py` and the model exists at `models/logreg/model.joblib`
- **THEN** the UI SHALL start and expose pages: Overview (metrics + charts), Inference (single + batch), and Reports (download static reports)
